<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Simen Haugo</title>
<link rel="stylesheet" href="style.css" type="text/css">
<link rel="stylesheet" href="portfolio.css" type="text/css">
<script src="analytics.js"></script>
</head>
<body>

<h2>Activity</h2>
<div class="post"><div class="date">Sep 2017</div><span>I gave a talk on visualizing computer programs (see <a href="./vdb/">transcript</a>)</span></div>
<div class="post"><div class="date">Aug 2017</div><span>I am now researching robotic vision at NTNU</span></div>
<div class="post"><div class="date">Aug 2017</div><span>We participated in the International Aerial Robotics Competition, again!</span></div>
<div class="post"><div class="date">Jun 2016</div><span>I got my Engineering Cybernetics degree</span></div>
<div class="post"><div class="date">Aug 2016</div><span>We participated in the International Aerial Robotics Competition</span></div>
<div class="post"><div class="date">Apr 2015</div><span>I co-founded <a href="https://ascendntnu.no/">Ascend NTNU</a></span></div>

<br>
<br>
<br>

<h2 id="writing">Writing</h2>
<div class="post"><div class="date">Sep 2017</div><a href="./vdb/">Visualizing computer programs (transcript)</a></div>
<div class="post"><div class="date">Jul 2017</div><a href="./v4l2_real_time/">v4l2 adventures: Real-time video capture for computer vision</a></div>
<div class="post"><div class="date">Jun 2017</div><a href="./v4l2_huffman/">v4l2 adventures: Missing Huffman table</a></div>

<br>
<br>
<br>

<h2 id="research">Research</h2>

<div class="project">
    <h3><span>computer vision</span>Continuous signed distance functions</h3>
    <video controls loop poster="gallery/csdf.png" width="300">
        <source src="gallery/csdf.mp4" type="video/mp4">
    </video>
    <p>To program a self-driving car, we need more than just a point cloud of its surroundings; to plan paths and obey rules, we need to know about the road, lanes, signs, pedestrians, other cars, and more. But information like this can only be had by imposing knowledge of our world and society into our algorithms that are, otherwise, oblivious to these concepts. This does, however, lead to a dilemma of how to represent all these objects and concepts in a computer program! Signed distance functions have been popular in computer graphics, and can possibly be a good tool for computer vision as well; in this paper I look at how.</p>
</div>

<div class="project" style="min-height: 270px; margin-bottom: 0px;">
    <h3><span>computer vision</span>Fitting 3D models to 3D reconstructions</h3>
    <img src="gallery/fitshape.gif"/>
    <p>While the above research looked at how to represent objects, that is only part of the job; to make use of it, we need to recognize these objects from sensor measurements: like color imagery, or depth data. In my master thesis I look at ways in which you can recover the 3D pose of objects, with the above representation, from color images and point clouds.</p>
</div>

<br>
<br>
<br>

<h2 id="projects">Projects</h2>

<div class="project" id="ascendntnu">
    <h3><span>robotics</span>Ascend NTNU</h3>
    <img src="gallery/ascend.png"/>
    <p>I helped start a robotics team at our university NTNU in 2015. Our common goal each year is to compete in the international aerial robotics competition (IARC), where student teams from universities around the world build drones that push the state of the art in technology. As a member in 2016 and 2017, we competed in the seventh mission, where the challenge is to herd independently moving roombas from one side to another in a 20x20m arena. Everything must be done autonomously by the drone - i.e. with the push of a single 'start' button - without GPS or external motion tracking systems.</p>
    <a href="https://ascendntnu.no/">homepage</a>
</div>

<div class="project">
    <h3><span>computer vision</span>Tracking robot vacuum cleaners</h3>
    <img src="gallery/roomba.jpg"/>
    <p>The seventh IARC challenge is to build a drone to herd 10 iRoomba vacuum cleaner robots across a 20m x 20m arena. The robots have sensors that the drone must physically touch, in order to affect their semi-random motion. But doing this assumes that you know where they are relative to the drone. With external sensing, like beacons or wall cameras, being banned, your only option is to spot them from the drone itself. I worked on the detection and tracking algorithm that we used to steer our drone in real-time and precisely interact with the robots.</p>
</div>

<div class="project" style="min-height: 350px;">
    <h3><span>computer vision</span>Inside-out position tracking</h3>
    <img src="gallery/grid.jpg"/>
    <p>A key step in overcoming the seventh IARC mission hinges on your drone's ability to know where it is in the arena - knowing that you're above a roomba is not useful, unless you also know where you are. The arena is patterned with a white grid of 1x1m tiles, that you can use for navigation, and a green edge indicating the herding line. Unfortunately, the arena is otherwise free to vary, and can have all sorts of distractions both inside and outside the grid, like sports markings, people or protection nets.</p>
</div>

<div class="project">
    <h3><span>tools</span>AI simulation and debugging tool for IARC</h3>
    <img src="gallery/iarcsim.gif"/>
    <p>This is one of my favorite projects, because I got to make a tool that was actually useful to many people. The members of the AI group at Ascend had requested a simulator that would let them test and debug their algorithms; so I built this tool that simulated only what was needed - no fancy physics or drone dynamics. I also added debugging tools like scrubbing back and forward in history, seeing a list of sent commands, robot status, recording video.</p>
</div>

<div class="project">
    <h3><span>tools</span>Mission status viewer</h3>
    <img src="gallery/mission.jpg"/>
    <p>Our robotics team built an autonomous drone that can fly along paths inside, without GPS or any external tracking system - only inside-out tracking. With all the things that can go wrong, it's important to have their status available in one place. This GUI tool gives us a live video feed from on-board cameras, lets us draw flight paths, see position state estimates, see commanded velocity and detected obstacles, reset the Kalman filter, and even see CPU load and temperatures. (But the best feature is the drone's tiny animated propellers.)</p>
</div>

<div class="project">
    <h3><span>tools</span>VDB</h3>
    <img src="gallery/vdb.png"/>
    <p>In his '86 paper <i>No Silver Bullet</i>, Fred Brooks suggested there is no single development in software engineering that promises even one tenfold productivity increase within a decade. Even today, doubts remain as to whether such a solution will ever come.</p>
    <p>Prototyped on a sunday morning in january 2016, this visualization and prototyping tool has been my personal silver bullet, that lets me interact and understand my programs. Check out the github link for more information.</p>
    <a href="https://github.com/lightbits/vdb">readme (github)</a>
</div>

<div class="project" style="min-height: 430px;">
    <h3><span>computer graphics</span>FRAKTAL</h3>
    <img src="gallery/fraktal.jpg"/>
    <p>I built this tool to render signed distance function scenes under my favorite type of diffuse lighting. The scene is defined in a shader file that can be reloaded on the fly. Rendering is done with path tracing on the GPU, and can be refined by letting it run longer. Despite being a hobby project, I got a chance to use it heavily for my master thesis, three years after initially building it.</p>
    <a href="https://github.com/lightbits/fraktal">github</a>
    <a href="https://github.com/lightbits/fraktal/blob/master/devlog/devlog.md">devlog</a>
</div>

<div class="project">
    <h3><span>computer graphics</span>Portal rendering</h3>
    <img src="gallery/portals.png"/>
    <p>I made this program to learn how portals can be rendered using OpenGL. This was a brilliant way to apply the theory I learned about rotation matrices from my robotics classes, into something visual; since figuring out where to render the scene from, behind the portal, is essentially a coordinate system transform! I also made a simple 3D test scene in Blender, and baked the lighting into a texture map using Cycles.</p>
</div>

<div class="footer">
<a href="https://lightbits.github.io/">Archive</a>
<a href="https://twitter.com/uint9">Twitter</a>
<a href="https://github.com/lightbits">Github</a>
</div>

<p style="text-align: center; font-size: 80%;">
    Simen Haugo Â© 2017<br>
    <a style="text-decoration:none;" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">BY-NC-SA</a> 4.0
</p>

</body>
</html>
