<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Simen Haugo</title>
<link rel="stylesheet" href="style.css" type="text/css">
<link rel="stylesheet" href="portfolio.css" type="text/css">
<script src="analytics.js"></script>
</head>
<body>
<img src="banner2.jpg"/>
<p>I research robotic vision at the Norwegian University of Science and Technology. I also mentor students at Ascend, our robotics group participating in IARC.</p>
<p>I do in fact answer e-mails.</p>
<div class="footer">
<a href="https://twitter.com/uint9">Twitter</a>
<a href="https://github.com/lightbits">Github</a>
<span>Contact: simen.haugo a ntnu.no</span>
</div>

<br>

<div class="project">
    <h3>Writing</h3>

<div class="post"><div class="date">May 2018</div><a href="./telerobot/">Working from home: A history of telerobot displays</a></div>

<div class="post"><div class="date">Apr 2018</div><a href="#project_sensors">30 dubious ways to find your robot without GPS</a></div>

<div class="post"><div class="date">Mar 2018</div><a href="./opengl/">A life of OpenGL programming</a></div>

<div class="post"><div class="date">Feb 2018</div><a href="./euler2/">Rotations and mathematical hammers II</a></div>

<div class="post"><div class="date">Jan 2018</div><a href="./euler/">Rotations and mathematical hammers I</a></div>

<div class="post"><div class="date">Dec 2017</div><a href="./papers2017/">Papers I loved in 2017</a></div>

<div class="post"><div class="date">Nov 2017</div><a href="./3dv17/">Lugging a 120cm tube across the world for a conference</a></div>

<div class="post"><div class="date">Oct 2017</div><a href="./cvtalk17/">(Lecture) If a stranger on the train asked you about computer vision</a></div>

<div class="post"><div class="date">Sep 2017</div><a href="./vdb/">(Lecture) Visualizing computer programs</a></div>

<div class="post"><div class="date">Jul 2017</div><a href="./v4l2_real_time/">Real-time video capture for computer vision</a></div>

<div class="post"><div class="date">Jun 2017</div><a href="./v4l2_huffman/">The case of Huffman and the missing table</a></div>

<div class="post"><div class="date">Aug 2016</div><span><a href="https://ascendntnu.no/publications/iarc16/">International Aerial Robotics Competition: a postmortem</a></span></div>

</div>

<div id="project_sensors" class="project" style="min-height: 270px; margin-bottom: 0px;">
    <h3>30 dubious ways to find your robot without GPS</h3>
    <img src="./gallery/sensors.png"/>
    <p>A book about figuring out where your robot is and what's around it. Current table of contents:</p>
    <ul>
        <li>Camera</li>
        <li>Spectral camera</li>
        <li>Depth camera</li>
        <li>Event camera</li>
        <li>Light-field camera</li>
        <li>Laser</li>
        <li>Radio</li>
        <li>Sound</li>
    </ul>
    <p><a href="./papers/sensors.pdf">sensors.pdf</a> (last updated July 2018)</p>
</div>
<br>
<br>

<div class="project">
    <h3>Continuous signed distance functions for 3D vision</h3>
    <video controls loop poster="gallery/csdf.png" width="300">
        <source src="gallery/csdf.mp4" type="video/mp4">
    </video>
    <p>In my master thesis I looked at how to add real-life objects to 3D reconstruction algorithms (like SLAM or SfM). The motivation being that a point cloud (or a mesh) is not very useful from a programmer perspective: to make a robot do something interesting, it needs to know stuff like 'this is is a door' or 'this is a hammer'. But we can only get that information by modelling our knowledge of the world, which leads to a dilemma of how to represent all these objects and concepts in a computer program.</p>
    <p>I eventually compressed my 50 page master thesis into an 8 page two-column paper that I submitted to <a href="http://3dv.org/">3DV</a>, a conference for 3D computer vision. I'll update this page when it becomes available.</p>
</div>

<div class="project" style="min-height: 270px; margin-bottom: 0px;">
    <h3>Fitting 3D models to 3D reconstructions</h3>
    <img src="gallery/fitshape.gif"/>
    <p>The above paper looked at how to model objects, but that is only part of the job. To make use of those models, we need to recognize them in the data (like color or depth images). In my master thesis below I have a more detailed discussion and experiments on ways to detect and localize objects modelled with signed distance functions. It's a bit longer, but in return it might be easier to read than the above paper.</p>
    <a href="papers/csdf-thesis.pdf"><img style="float:none;display:inline-block;height:128px;width:inherit;vertical-align:middle;" src="papers/csdf-thesis-icon.png"/>csdf-thesis.pdf</a>
</div>

<br>
<br>
<br>

<!--
<div class="project">
    <h3>Recipes</h3>
    <img src="./recipes/strawberries/IMG_6932.JPG">
    <p>I sometimes find myself with an ingredient but no clue how to use it.</p>
    <span><a href="./recipes/strawberries/">Sourdough &amp; Strawberries</a>. . . .</span>
    <span class="date">Feb 2018</span>
    <br>
    <span><a href="">Oats</a> . . . . . . . . . . . . . . . . . . . . .</span>
    <span class="date">Jun 2017</span>
    <br>
    <span><a href="">Balsamico</a> . . . . . . . . . . . . . . . .</span>
    <span class="date">Dec 2017</span>
    <br>
    <span><a href="">Hummus</a> . . . . . . . . . . . . . . . . .</span>
    <span class="date">Dec 2017</span>
    <br>
    <span><a href="">Spaghetti &amp; Linseeds</a> . . . . . . .</span>
    <span class="date">Dec 2017</span>
    <br>
    <span><a href="">Lentils</a> . . . . . . . . . . . . . . . . . . .</span>
    <span class="date">Dec 2017</span>
    <br>
</div>
-->

<div class="project" id="ascendntnu">
    <h3>Ascend NTNU</h3>
    <img src="gallery/ascend.png"/>
    <p>I helped start a robotics team at my university (NTNU) in 2015, with the hope of participating in the International Aerial Robotics Competition, where students from universities around the globe make "autonomous" drones that do cool stuff without a pilot - e.g. flying through an office complex, snatching a USB thumbdrive and replacing it with a fake one.</p>

    <p>Somewhat miraculously, we did compete and we did pretty well in the seventh mission, where the challenge is to herd robot vacuum cleaners (Roombas) from one side to another in a 20x20 meter arena. Everything must be done with the push of a single button.</p>

    <p>Ascend is still very active, and recruits new members each year. Still with the shared goal of competing in IARC where, at the time of writing (2017), the seventh IARC mission has yet to be solved. You can follow the team's progress at our homepage.</p>

    <a href="https://ascendntnu.no/">homepage</a>
</div>

<div class="project">
    <h3>Tracking robot vacuum cleaners</h3>
    <img src="gallery/roomba.jpg"/>
    <p>As part of my work at Ascend, I worked on the vacuum cleaner tracking problem. The competition challenge is to build a drone to herd 10 iRoombas across a 20m x 20m arena. The robots have sensors that the drone can physically touch to steer their motion path.</p>

    <p>But physically touching it or landing on it means you need to know its position. With external sensing, like beacons or wall cameras, being banned, your only option is to see them from the drone itself.</p>

    <p>This project was an interesting learning lesson. I spent six months, as part of my pre-master project on a method that worked by rendering a 3D model of the robot and adjusting the pose estimate to make the render appear identical with the camera image. While insanely cool, it was also insanely complicated, was not predictable, and ran way too slowly. The better approach only took an evening to implement and works by just finding colored blobs.</p>

    <p>You can check out my project report at the link below. I go into detail about computer vision basics, like how to estimate 3D poses, how to work with fisheye cameras, and different ways to detect objects. I also describe the fancy 3D rendering method that ultimately wasn't useful.</p>
    <a href="papers/roomba.pdf"><img style="float:none;display:inline-block;height:128px;width:inherit;vertical-align:middle;" src="papers/roomba-icon.png"/>roomba.pdf</a>
</div>

<div class="project" style="min-height: 350px;">
    <h3>Inside-out position tracking</h3>
    <img src="gallery/grid.jpg"/>
    <p>As part of my work at Ascend I also worked on the inside-out position tracking problem. A key step in overcoming the seventh IARC mission hinges on your drone's ability to know where it is in the arena - knowing that you're above a roomba is not useful, unless you also know where you are. The arena is patterned with a white grid of 1x1m tiles, that you can use for navigation, and a green edge indicating the herding line. Unfortunately, the arena is otherwise free to vary, and can have all sorts of distractions both inside and outside the grid, like sports markings, people or protection nets.</p>
</div>

<div class="project">
    <h3>AI simulation and debugging tool for IARC</h3>
    <img src="gallery/iarcsim.gif"/>
    <p>This is one of my favorite projects, because I got to make a tool that was actually useful to many people. The members of the AI group at Ascend had requested a simulator that would let them test and debug their algorithms; so I built this tool that simulated only what was needed - no fancy physics or drone dynamics. I also added debugging tools like scrubbing back and forward in history, seeing a list of sent commands, robot status, recording video.</p>
</div>

<div class="project">
    <h3>Mission status viewer</h3>
    <img src="gallery/mission.jpg"/>
    <p>Our robotics team built an autonomous drone that can fly along paths inside, without GPS or any external tracking system - only inside-out tracking. With all the things that can go wrong, it's important to have their status available in one place. This GUI tool gives us a live video feed from on-board cameras, lets us draw flight paths, see position state estimates, see commanded velocity and detected obstacles, reset the Kalman filter, and even see CPU load and temperatures. (But the best feature is the drone's tiny animated propellers.)</p>
</div>

<div class="project">
    <h3>VDB</h3>
    <img src="gallery/vdb.png"/>
    <p>In his '86 paper <i>No Silver Bullet</i>, Fred Brooks suggested there is no single development in software engineering that promises even one tenfold productivity increase within a decade. Even today, doubts remain as to whether such a solution will ever come.</p>
    <p>Hacked together on a sunday morning in january 2016, this visualization and prototyping tool has been my personal silver bullet.</p>
    <a href="https://github.com/lightbits/vdb">readme (github)</a>
    <br>
    <a href="./vdb/">A talk I gave in 2017 (transcript)</a>
</div>

<div class="project" style="min-height: 430px;">
    <h3>FRAKTAL</h3>
    <img src="gallery/fraktal.jpg"/>
    <p>I built this tool to render signed distance function scenes under my favorite type of diffuse lighting. The scene is defined in a shader file that can be reloaded on the fly. Rendering is done with path tracing on the GPU, and can be refined by letting it run longer. Despite being a hobby project, I got a chance to use it heavily for my master thesis, three years after initially building it.</p>
    <p>You can grab the source at github and try it out if you can figure it out. You can also read my dev log, where you can see the early, embarrassingly noisy, renders.</p>
    <a href="https://github.com/lightbits/fraktal">github</a>
    <a href="https://github.com/lightbits/fraktal/blob/master/devlog/devlog.md">devlog</a>
</div>

<div class="project">
    <h3>Portal rendering</h3>
    <img src="gallery/portals.png"/>
    <p>I made this program to learn how portals can be rendered using OpenGL. This was a brilliant way to apply the theory I learned about rotation matrices from my robotics classes, into something visual; since figuring out where to render the scene from, behind the portal, is essentially a coordinate system transform! I also made a simple 3D test scene in Blender, and baked the lighting into a texture map using Cycles.</p>
</div>

<p class="attrib">
    Simen Haugo © 2018<br>
    <a style="text-decoration:none;" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">BY-NC-SA</a> 4.0
</p>

</body>
</html>
