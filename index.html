<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Simen Haugo</title>
<link rel="stylesheet" href="style.css" type="text/css">
<style type="text/css">
.post { display:flex; padding-bottom:.5em;}
.good a { background-color: #FFE6A4; }
.date { font-style:italic; width:5em; text-align:center; padding-right:.5em;}
.project img { float: right; width: 250px; padding-left: 12px; }
.project video { float: right; width: 250px; padding-left: 12px; }
.project { max-width: 640px; min-height: 350px; margin-bottom: 100px; }
.project h3 { border-top:1px solid #000; border-bottom:1px solid #000;font-weight: normal; text-align: center; padding: 8px 0; }
@media screen and (max-width: 600px){
.date { display: none; }
.project img { width: 100%; margin-bottom: 12px; }
.project video { width: 100%; margin-bottom: 12px; }
}
</style>
</head>
<body>
<h1>Simen Haugo</h1>
<p>Robotic vision researcher at the Norwegian University of Science and Technology, and mentor for the student robotics group Ascend NTNU.</p>
<div class="footer">
<a href="https://twitter.com/uint9">Twitter</a>
<a href="https://github.com/lightbits">Github</a>
<span>Contact: (first name).(last name)@ntnu.no</span>
</div>

<br>

<div class="project">
<h3>Writing</h3>
<p>My favorites are highlighted in yellow.</p>

<div class="post"><div class="date">Aug 2018</div><a href="./betterpractice/">Better research practice</a></div>

<div class="post good"><div class="date">May 2018</div><a href="./telerobot/">Working from home: A history of telerobot displays</a></div>

<div class="post good"><div class="date">Apr 2018</div><a href="#project_sensors">30 dubious ways to find your robot without GPS</a></div>

<div class="post"><div class="date">Mar 2018</div><a href="./opengl/">A life of OpenGL programming</a></div>

<div class="post"><div class="date">Feb 2018</div><a href="./euler2/">Rotations and mathematical hammers II</a></div>

<div class="post good"><div class="date">Jan 2018</div><a href="./euler/">Rotations and mathematical hammers I</a></div>

<div class="post"><div class="date">Dec 2017</div><a href="./papers2017/">Papers I loved in 2017</a></div>

<div class="post"><div class="date">Nov 2017</div><a href="./3dv17/">Lugging a 120cm tube across the world for a conference</a></div>

<div class="post"><div class="date">Oct 2017</div><a href="./cvtalk17/">(Lecture) If a stranger on the train asked you about computer vision</a></div>

<div class="post good"><div class="date">Sep 2017</div><a href="./vdb/">(Lecture) Visualizing computer programs</a></div>

<div class="post"><div class="date">Jul 2017</div><a href="./v4l2_real_time/">Real-time video capture for computer vision</a></div>

<div class="post"><div class="date">Jun 2017</div><a href="./v4l2_huffman/">The case of Huffman and the missing table</a></div>

<div class="post"><div class="date">Aug 2016</div><span><a href="https://ascendntnu.no/publications/iarc16/">International Aerial Robotics Competition: a postmortem</a></span></div>

<div class="post"><div class="date">Jul 2013</div><span><a href="http://9bitscience.blogspot.com/2013/07/raymarching-distance-fields_14.html">Raymarching Distance Fields (old blog)</a></span></div>

</div>

<div id="project_sensors" class="project" style="min-height: 270px; margin-bottom: 0px;">
    <h3>30 dubious ways to find your robot without GPS</h3>
    <img src="./gallery/sensors.png"/>
    <p>A book about figuring out where your robot is and what's around it. Current table of contents:</p>
    <ul>
        <li>Camera</li>
        <li>Spectral camera</li>
        <li>Depth camera</li>
        <li>Event camera</li>
        <li>Light-field camera</li>
        <li>Laser</li>
        <li>Radio</li>
        <li>Sound</li>
    </ul>
    <p><a href="./papers/sensors.pdf">sensors.pdf</a> (last updated July 2018)</p>
</div>
<br>
<br>

<div class="project">
    <h3>Continuous signed distance functions for 3D vision</h3>
    <video controls loop poster="gallery/csdf.png" width="300">
        <source src="gallery/csdf.mp4" type="video/mp4">
    </video>
    <p>In my master thesis I looked at how to add real-life objects to 3D reconstruction algorithms (like SLAM or SfM). The motivation being that a point cloud (or a mesh) is not very useful from a programmer perspective: to make a robot do something interesting, it needs to know stuff like 'this is is a door' or 'this is a hammer'. But we can only get that information by modelling our knowledge of the world, which leads to a dilemma of how to represent all these objects and concepts in a computer program. I eventually compressed my 50 page master thesis into an 8 page two-column paper that I submitted to <a href="http://3dv.org/">3DV</a>, a conference for 3D computer vision.</p>
    <p><a href="papers/haugo2017continuous.pdf">Continuous signed distance functions for 3D vision</a><br>Simen Haugo, Annette Stahl, Edmund Brekke.</p>
</div>

<div class="project" style="min-height: 270px; margin-bottom: 0px;">
    <h3>Fitting 3D models to 3D reconstructions</h3>
    <video controls loop poster="gallery/fitshape.png" width="300">
        <source src="gallery/fitshape.webm" type="video/mp4">
    </video>
    <p>The above paper looked at how to model objects, but that is only part of the job. To make use of those models, we need to recognize them in the data (like color or depth images). In my master thesis below I have a more detailed discussion and experiments on ways to detect and localize objects modelled with signed distance functions. It's a bit longer, but in return it might be easier to read than the above paper.</p>
    <a href="papers/csdf-thesis.pdf"><img style="float:none;display:inline-block;height:128px;width:inherit;vertical-align:middle;" src="papers/csdf-thesis-icon.png"/>csdf-thesis.pdf</a>
</div>

<br>
<br>
<br>

<div class="project" id="ascendntnu">
    <h3>Ascend NTNU</h3>
    <img src="gallery/ascend.png"/>
    <p>I helped start a robotics team at my university (NTNU) in 2015, with the hope of participating in the International Aerial Robotics Competition, where students from universities around the globe make "autonomous" drones that do cool stuff without a pilot - e.g. flying through an office complex, snatching a USB thumbdrive and replacing it with a fake one.</p>

    <p>You can follow our team's progress at our homepage.</p>

    <a href="https://ascendntnu.no/">homepage</a>
</div>

<div class="project">
    <h3>Tracking robot vacuum cleaners</h3>
    <img src="gallery/roomba.jpg"/>
    <p>At Ascend I worked on tracking robotic vacuum cleaners from a camera. One method I tried was to render a 3D model of the robot and wiggle the pose parameters to match the image. It didn't work very well. A far better approach was to use classical connected components, color space transformation and thresholding.</p>

    <p>The methods and failures are described in my project report.</p>
    <a href="papers/roomba.pdf"><img style="float:none;display:inline-block;height:128px;width:inherit;vertical-align:middle;" src="papers/roomba-icon.png"/>roomba.pdf</a>
</div>

<div class="project" style="min-height: 350px;">
    <h3>Inside-out position tracking</h3>
    <img src="gallery/grid.jpg"/>
    <p>At Ascend I worked on inside-out position tracking from a drone. A key step in overcoming the seventh IARC mission hinges on your drone's ability to know where it is in the arena - knowing that you're above a roomba is not useful, unless you also know where you are. The arena is patterned with a white grid of 1x1m tiles, that you can use for navigation, and a green edge indicating the herding line. Unfortunately, the arena is otherwise free to vary, and can have all sorts of distractions both inside and outside the grid, like sports markings, people or protection nets.</p>
</div>

<div class="project">
    <h3>AI simulation and debugging tool for IARC</h3>
    <video controls loop poster="gallery/iarcsim.png" width="300">
        <source src="gallery/iarcsim.webm" type="video/mp4">
    </video>
    <p>This is one of my favorite projects, because I got to make a tool that was actually useful to many people. The members of the AI group at Ascend had requested a simulator that would let them test and debug their algorithms; so I built this tool that simulated only what was needed - no fancy physics or drone dynamics. I also added debugging tools like scrubbing back and forward in history, seeing a list of sent commands, robot status, recording video.</p>
</div>

<div class="project">
    <h3>Mission status viewer</h3>
    <img src="gallery/mission.jpg"/>
    <p>Our robotics team built an autonomous drone that can fly along paths inside, without GPS or any external tracking system - only inside-out tracking. With all the things that can go wrong, it's important to have their status available in one place. This GUI tool gives us a live video feed from on-board cameras, lets us draw flight paths, see position state estimates, see commanded velocity and detected obstacles, reset the Kalman filter, and even see CPU load and temperatures. (But the best feature is the drone's tiny animated propellers.)</p>
</div>

<div class="project">
    <h3>VDB</h3>
    <img src="gallery/vdb.png"/>
    <p>In his '86 paper <i>No Silver Bullet</i>, Fred Brooks suggested there is no single development in software engineering that promises even one tenfold productivity increase within a decade. Even today, doubts remain as to whether such a solution will ever come.</p>
    <p>Hacked together on a sunday morning in january 2016, this visualization and prototyping tool has been my personal silver bullet.</p>
    <a href="https://github.com/lightbits/vdb">readme (github)</a>
    <br>
    <a href="./vdb/">A talk I gave in 2017 (transcript)</a>
</div>

<div class="project" style="min-height: 430px;">
    <h3>FRAKTAL</h3>
    <img src="gallery/fraktal.jpg"/>
    <p>I built a tool to render signed distance function scenes under my favorite type of diffuse lighting. The scene is defined in a shader file that can be reloaded on the fly. Rendering is done with path tracing on the GPU, and can be refined by letting it run longer. I used the tool to generate the video and images in my master thesis.</p>
    <p>The source is on github along with a development diary.</p>
    <a href="https://github.com/lightbits/fraktal">github</a>
    <a href="https://github.com/lightbits/fraktal/blob/master/devlog/devlog.md">devlog</a>
</div>

<p class="attrib">
    Simen Haugo © 2019<br>
    <a style="text-decoration:none;" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">BY-NC-SA</a> 4.0
</p>

</body>
</html>
