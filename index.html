<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Simen Haugo</title>
<link rel="stylesheet" href="style.css" type="text/css">
<link rel="stylesheet" href="portfolio.css" type="text/css">
<script src="analytics.js"></script>
</head>
<body>

<h2>Activity</h2>
<div class="post"><div class="date">Oct 2017</div><span>I gave a talk on computer vision (see <a href="./cvtalk17/">video</a>)</span></div>
<div class="post"><div class="date">Sep 2017</div><span>I gave a talk on visualizing computer programs (see <a href="./vdb/">transcript</a>)</span></div>
<div class="post"><div class="date">Aug 2017</div><span>I am now researching robotic vision at NTNU</span></div>
<div class="post"><div class="date">Aug 2017</div><span>We participated in the International Aerial Robotics Competition, again!</span></div>
<div class="post"><div class="date">Jun 2016</div><span>I got my Engineering Cybernetics degree</span></div>
<div class="post"><div class="date">Aug 2016</div><span>We participated in the International Aerial Robotics Competition</span></div>
<div class="post"><div class="date">Apr 2015</div><span>I co-founded <a href="https://ascendntnu.no/">Ascend NTNU</a></span></div>

<br>
<br>
<br>

<h2 id="writing">Writing</h2>
<div class="post"><div class="date">Oct 2017</div><a href="./cvtalk17/">If a stranger on the train asked you about computer vision (video)</a></div>
<div class="post"><div class="date">Sep 2017</div><a href="./vdb/">Visualizing computer programs (transcript)</a></div>
<div class="post"><div class="date">Jul 2017</div><a href="./v4l2_real_time/">v4l2 adventures: Real-time video capture for computer vision</a></div>
<div class="post"><div class="date">Jun 2017</div><a href="./v4l2_huffman/">v4l2 adventures: Missing Huffman table</a></div>

<br>
<br>
<br>

<h2 id="research">Research</h2>

<div class="project">
    <h3>Continuous signed distance functions</h3>
    <video controls loop poster="gallery/csdf.png" width="300">
        <source src="gallery/csdf.mp4" type="video/mp4">
    </video>
    <p>In my master thesis I looked at how to model and integrate man-made objects into 3D scene understanding algorithms. The motivation being that, to program a self-driving car, we want more than just a point cloud of its surroundings. To plan paths and obey rules, we want to know about things like lanes, signs, pedestrians, other cars, and so on. But information like that can only be had by imposing knowledge about our society into algorithms that are, otherwise, oblivious to such concepts. This leads to a dilemma of how to represent all these objects and concepts in a computer program.</p>
</div>

<div class="project" style="min-height: 270px; margin-bottom: 0px;">
    <h3>Fitting 3D models to 3D reconstructions</h3>
    <img src="gallery/fitshape.gif"/>
    <p>While the above research looked at how to represent objects, that is only part of the job; to make use of it, we need to recognize these objects from sensor measurements: like color imagery, or depth data. In my master thesis I look at ways in which you can recover the 3D pose of objects, with the above representation, from color images and point clouds.</p>
</div>

<br>
<br>
<br>

<h2 id="projects">Projects</h2>

<div class="project" id="ascendntnu">
    <h3>Ascend NTNU</h3>
    <img src="gallery/ascend.png"/>
    <p>I helped start a robotics team at my university (NTNU) in 2015, with the hope of participating in the International Aerial Robotics Competition, where students from universities around the globe make "autonomous" drones that do cool stuff without a pilot - e.g. flying through an office complex, snatching a USB thumbdrive and replacing it with a fake one.</p>

    <p>Somewhat miraculously, we did compete and we did pretty well in the seventh mission, where the challenge is to herd robot vacuum cleaners (Roombas) from one side to another in a 20x20 meter arena. Everything must be done with the push of a single button.</p>

    <p>Ascend is still very active, and recruits new members each year. Still with the shared goal of competing in IARC where, at the time of writing (2017), the seventh IARC mission has yet to be solved. You can follow the team's progress at our homepage.</p>

    <a href="https://ascendntnu.no/">homepage</a>
</div>

<div class="project">
    <h3>Tracking robot vacuum cleaners</h3>
    <img src="gallery/roomba.jpg"/>
    <p>As part of my work at Ascend, I worked on the vacuum cleaner tracking problem. The competition challenge is to build a drone to herd 10 iRoombas across a 20m x 20m arena. The robots have sensors that the drone can physically touch to steer their motion path.</p>

    <p>But physically touching it or landing on it means you need to know its position. With external sensing, like beacons or wall cameras, being banned, your only option is to see them from the drone itself.</p>

    <p>This project was an interesting learning lesson. I spent six months, as part of my pre-master project on a method that worked by rendering a 3D model of the robot and adjusting the pose estimate to make the render appear identical with the camera image. While insanely cool, it was also insanely complicated, was not predictable, and ran way too slowly. The better approach only took an evening to implement and works by just finding colored blobs.</p>
</div>

<div class="project" style="min-height: 350px;">
    <h3>Inside-out position tracking</h3>
    <img src="gallery/grid.jpg"/>
    <p>As part of my work at Ascend I also worked on the inside-out position tracking problem. A key step in overcoming the seventh IARC mission hinges on your drone's ability to know where it is in the arena - knowing that you're above a roomba is not useful, unless you also know where you are. The arena is patterned with a white grid of 1x1m tiles, that you can use for navigation, and a green edge indicating the herding line. Unfortunately, the arena is otherwise free to vary, and can have all sorts of distractions both inside and outside the grid, like sports markings, people or protection nets.</p>
</div>

<div class="project">
    <h3>AI simulation and debugging tool for IARC</h3>
    <img src="gallery/iarcsim.gif"/>
    <p>This is one of my favorite projects, because I got to make a tool that was actually useful to many people. The members of the AI group at Ascend had requested a simulator that would let them test and debug their algorithms; so I built this tool that simulated only what was needed - no fancy physics or drone dynamics. I also added debugging tools like scrubbing back and forward in history, seeing a list of sent commands, robot status, recording video.</p>
</div>

<div class="project">
    <h3>Mission status viewer</h3>
    <img src="gallery/mission.jpg"/>
    <p>Our robotics team built an autonomous drone that can fly along paths inside, without GPS or any external tracking system - only inside-out tracking. With all the things that can go wrong, it's important to have their status available in one place. This GUI tool gives us a live video feed from on-board cameras, lets us draw flight paths, see position state estimates, see commanded velocity and detected obstacles, reset the Kalman filter, and even see CPU load and temperatures. (But the best feature is the drone's tiny animated propellers.)</p>
</div>

<div class="project">
    <h3>VDB</h3>
    <img src="gallery/vdb.png"/>
    <p>In his '86 paper <i>No Silver Bullet</i>, Fred Brooks suggested there is no single development in software engineering that promises even one tenfold productivity increase within a decade. Even today, doubts remain as to whether such a solution will ever come.</p>
    <p>Prototyped on a sunday morning in january 2016, this visualization and prototyping tool has been my personal silver bullet, that lets me interact and understand my programs. Check out the github link for more information.</p>
    <a href="https://github.com/lightbits/vdb">readme (github)</a>
</div>

<div class="project" style="min-height: 430px;">
    <h3>FRAKTAL</h3>
    <img src="gallery/fraktal.jpg"/>
    <p>I built this tool to render signed distance function scenes under my favorite type of diffuse lighting. The scene is defined in a shader file that can be reloaded on the fly. Rendering is done with path tracing on the GPU, and can be refined by letting it run longer. Despite being a hobby project, I got a chance to use it heavily for my master thesis, three years after initially building it.</p>
    <p>You can grab the source at github and try it out if you can figure it out. You can also read my dev log, where you can see the early, embarrassingly noisy, renders.</p>
    <a href="https://github.com/lightbits/fraktal">github</a>
    <a href="https://github.com/lightbits/fraktal/blob/master/devlog/devlog.md">devlog</a>
</div>

<div class="project">
    <h3>Portal rendering</h3>
    <img src="gallery/portals.png"/>
    <p>I made this program to learn how portals can be rendered using OpenGL. This was a brilliant way to apply the theory I learned about rotation matrices from my robotics classes, into something visual; since figuring out where to render the scene from, behind the portal, is essentially a coordinate system transform! I also made a simple 3D test scene in Blender, and baked the lighting into a texture map using Cycles.</p>
</div>

<div class="footer">
<a href="https://lightbits.github.io/">Archive</a>
<a href="https://twitter.com/uint9">Twitter</a>
<a href="https://github.com/lightbits">Github</a>
</div>

<p class="attrib">
    Simen Haugo Â© 2017<br>
    <a style="text-decoration:none;" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">BY-NC-SA</a> 4.0
</p>

</body>
</html>
