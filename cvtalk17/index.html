<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>If a stranger on the train asked you about computer vision</title>
<link rel="stylesheet" href="../style.css" type="text/css">
<script src="../analytics.js"></script>
</head>
<body>

<h1>If a stranger on the train asked you about computer vision</h1>

<p>I gave an introductory lecture about computer vision for the new members at my university's robotics club <a href="https://ascendntnu.no/">Ascend NTNU</a>. I talked about how computer vision can be used not just to make robots that can follow lines or catch balls, but how it enables both humans and robots to measure stuff we care about, and make decisions based on that information to achieve the outcomes we want: be it managing our farms intelligently with fewer resources, refining our scientific theories to better match nature, or providing data about our changing climate to decision makers.</p>

<div style="position: relative; padding-bottom: 60%; width:100%;">
<iframe style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" width="560" height="315" src="https://www.youtube.com/embed/qR8jiQ6PqcM" frameborder="0" allowfullscreen></iframe>
</div>

<p>There's a ton of inspiring projects that I wish I had heard of during my studies, and I wanted to share them with our eager new members. But I also felt like I had to give some technical information that would be useful to actually solve problems. Instead of doing the reasonable thing and saving that for its own talk, I decided to cram it into the same lecture!</p>

<p><a href="https://lightbits.github.io/cvtalk17/slides.pdf">Download slides (.pdf)</a></p>

<p>Maybe you were inspired by the projects I refer to in the talk, in which case I recommend you check out their homepages below.</p>
<ul>
    <li><a href="https://www.disneyresearch.com/publication/playing-catch-and-juggling-with-a-humanoid-robot/">Disney research: Playing catch and juggling with a humanoid robot</a></li>

    <li><a href="http://www.adigo.no/portfolio/asterix/">Adigo: Asterix</a></li>
    <li><a href="http://flourish-project.eu/">Flourish project</a></li>
    <li><a href="https://indico.cern.ch/event/397113/contributions/1837827/attachments/1213258/1890407/ACAT16_Ariel_v3.pdf">Image processing, computer vision and deep learning: new approaches to the analysis and physics interpretation of LHC events</a></li>
    <li><a href="http://imerso.com/">Imerso: Mobile 3D scanning</a></li>
    <li><a href="https://www.planet.com/">Planet Labs</a></li>
    <li><a href="https://www.youtube.com/watch?v=0VIwuCaTHPM">Pattern Hough transform for crop row detection</a></li>

    <li><a href="http://domedb.perception.cs.cmu.edu/">CMU Panoptic Dataset</a></li>
    <li><a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">OpenPose: Real-Time Multi-Person Keypoint Detection Library for Body, Face, and Hands</a></li>

    <li><a href="https://dl.acm.org/citation.cfm?id=3036661">Hand-Clapping Games with a Baxter Robot</a></li>
</ul>

<div class="footer">
<a href="https://lightbits.github.io/">Archive</a>
<a href="https://twitter.com/uint9">Twitter</a>
<a href="https://github.com/lightbits">Github</a>
</div>

<p class="attrib">
    Simen Haugo Â© 2017<br>
    <a style="text-decoration:none;" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">BY-NC-SA</a> 4.0
</p>

</body>
</html>
